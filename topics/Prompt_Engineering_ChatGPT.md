# ChatGPT
Es una modelo de inteligencia artificial que genera lenguaje estructurado.

- [ ] [Como escribir prompts en ChatGPT](https://github.com/r3card0/Data_AI_foundations/blob/main/topics/Prompt_Engineering_ChatGPT.md#como-escribir-prompts-en-chatgpt)
- [ ] [T√©cnicas b√°sicas de prompt engineering](https://github.com/r3card0/Data_AI_foundations/blob/main/topics/Prompt_Engineering_ChatGPT.md#t%C3%A9cnicas-b%C3%A1sicas-de-prompt-engineering)
- [ ] [T√©cnicas avanzadas de prompt engineering](https://github.com/r3card0/Data_AI_foundations/blob/main/topics/Prompt_Engineering_ChatGPT.md#t%C3%A9cnicas-avanzadas-de-prompt-engineering)
- [ ] [Casos de uso](https://github.com/r3card0/Data_AI_foundations/blob/main/topics/Prompt_Engineering_ChatGPT.md#casos-de-uso-de-chatgpt)

# Como escribir prompts en ChatGPT
Un prompt es una pregunta que se le hace a ChatGPT. Es recomendable considerar la fecha del tema porque los modelos pueden tener informaci√≥n actuializada haste la fecha considerada. Por ejemplo, ChatGPT, en su lanzamiento, tuvo informaci√≥n hasta septiembre del 2021.

## Estructura de un prompt
Un prompt tiene los siguientes puntos que le dan estructura y son: *instrucci√≥n, contexto, inputs y outputs*. Cabe se√±alar, que no es necesario que los 4 puntos est√°n inlcuidos en un prompt.

#### Instrucci√≥n
Se trata de la tarea o instrucci√≥n a resolver. Es la tarea solicitada al modelo (ChatGPT). Esta solicitud, puede ser una pregunta simple o compleja. 

Ejemplo:
```
¬øqu√© es una base de datos relacional?
```


#### Contexto
Es informaci√≥n adicional que se le proporciona al modelo para mejorar su respuesta. 

Ejemplo:
```
ahora, explica a un ni√±o de 8 a√±os, que es una base de datos relacional con ejemplos que el entienda
```

#### Inputs
Es informaci√≥n adicional que se le proporciona al modelo para que realice comparaciones y mejorar su respuesta. Esto se da cuando se le proporciona un ejemplo al modelo para que a partir de este mejore su respuesta. Se porporciona mas detalle.

Ejemplo:
```
explicale al ni√±o, la diferencia entre la base de datos relacional y las tablas de un archivo excel
```


```
explicalo nuevamente cambiando la palabra carpeta por caja de carton, porque el ni√±o no usa carpetas
```

#### Outputs
Se refiere cuando se le solicita al modelo, que la respuesta la de en una estructura deseada, como por ejemplo que de una tabla de comparaci√≥n, o que proporcione divisiones por categoria a trav√©s de bullets num√©ricos o no num√©ricos. Este es opcional y se da cuando se brinda mas detalle al modelo para que mejore su respuesta.

```
nuevamente, explicale la diferencia entre ambas tecnologias pero ahora con una historia de piratas donde se enfrenten a dinosarios y tiburones que tienen piernas de humano y pueden respirar tanto en la superficie como en el mar
```

[ver conversacion üó∫](https://chat.openai.com/share/1f4a1d79-c8eb-4174-bfe2-ad525e2aa9b4)


# T√©cnicas b√°sicas de prompt engineering
* Zero-shot y One-shot Prompting
* Chain-of-Thought Prompting
* Optimizar resultados con estructuras de texto espec√≠ficas
* Mejorar resultados iterando


El prop√≥sito de usar *Chain-of-thought* con LLM como ChatGPT, es generar texto estructurado y coherente a partir de una l√≠nea de pensamiento como ejemplo

La principal ventaja del *zero-shot* prompting es que no requiere datos de entrenamiento adicionales

La *iteraci√≥n* en prompt engineering es una t√©cnica para orientar al modelo a dar mejores respuestas con base al feedback de sus respuestas anteriores

La principal diferencia entre *few-shot* prompting y *one-prompting* es que *few-shot* prompting puede obtener una precisi√≥n mayor con unos cuantos ejemplos de entrenamiento. *One-shot* prompting puede ser menos preciso debido a que utiliza solo un ejemplo de entramiento.

# T√©cnicas avanzadas de prompt engineering
* [Role play](https://github.com/r3card0/Data_AI_foundations/blob/main/topics/Prompt_Engineering_ChatGPT.md#role-play)
* [knowledge Generation](https://github.com/r3card0/Data_AI_foundations/blob/main/topics/Prompt_Engineering_ChatGPT.md#knowledge-generation)
* [Knowledge Integration](https://github.com/r3card0/Data_AI_foundations/blob/main/topics/Prompt_Engineering_ChatGPT.md#knowledge-integration)
* [Hyper par√°metros de ChatGPT](https://github.com/r3card0/Data_AI_foundations/blob/main/topics/Prompt_Engineering_ChatGPT.md#hiper-par√°metros-de-chatgpt)

## Role play
Es una tecnica usada para indicarle al model que **actue como . .**. El modelo toma la personalidad que le solicitamos y a partir de este, proporciona respuestas

## Knowledge Generation
### Knowledge Generation / Knowledge Integration
Son t√©cnicas usadas para mejorar los modelos de lenguaje y que incluye la capacidad de generar y/o incorporar conocimiento o informaci√≥n para ayudar al modelo a generar respuestas mucho mas precisas.


üçÖ ¬øQue me puedes decir del concepto de Knowledge Generation aplicado en prompts?

ü§ñ ¬°Hola! En el contexto de la inteligencia artificial y los modelos de lenguaje como GPT-3.5, el concepto de "Knowledge Generation" (Generaci√≥n de Conocimiento) *se refiere a la capacidad del modelo para generar informaci√≥n nueva y relevante en funci√≥n de los datos y el contexto proporcionados en el prompt.*

ü§ñ Cuando aplicas el concepto de Knowledge Generation en prompts, *est√°s aprovechando la capacidad del modelo para comprender el contexto y generar respuestas que no solo se basan en la informaci√≥n existente en sus datos de entrenamiento, sino que tambi√©n incorporan una capacidad para razonar, inferir y, en ciertos casos, generar contenido nuevo.*

ü§ñ En la pr√°ctica, al utilizar prompts espec√≠ficos, puedes solicitar al modelo que genere informaci√≥n o respuestas que vayan m√°s all√° de la informaci√≥n que ha sido directamente alimentada durante su entrenamiento. Esto permite que el modelo sea m√°s vers√°til y capaz de ofrecer respuestas √∫nicas y contextualmente relevantes en una amplia gama de situaciones.

ü§ñ üëâ Es importante se√±alar que, aunque los modelos de lenguaje como GPT-3.5 pueden generar conocimiento nuevo hasta cierto punto, no tienen una comprensi√≥n real del mundo y pueden producir respuestas que no son necesariamente precisas o ver√≠dicas. Por lo tanto, es fundamental interpretar y validar la informaci√≥n generada por estos modelos en funci√≥n de la precisi√≥n y la coherencia con el conocimiento establecido.

Un buen ejemplo es la capacidad del LLMs de crear historias. En base a un contexto que se proporciona en el prompt, el modelo crea una historia.

üçÖ Crea una historia donde haya dos personajes principales, un unicornio con poderes magicos, que hable y que cague dulces y un tiranosaurio rex que habla, le gusta mucho jugar videojuegos y sea un poco travieso. Ambos personajes no miden mas de 1.5m y siempre estan juntos viviendo aventuras en un mundo donde hay bosques magicos y piratas de alta mar.

ü§ñ *En un mundo m√°gico lleno de bosques encantados y oc√©anos misteriosos, viv√≠an dos amigos inusuales: Sparkle, un peque√±o unicornio con poderes m√°gicos y la habilidad √∫nica de cagar dulces, y Rex, un tiranosaurio rex parlante aficionado a los videojuegos y un tanto travieso. A pesar de sus diferencias, ambos med√≠an no m√°s de 1.5 metros y compart√≠an una amistad √∫nica y especial.*

ü§ñ *Un d√≠a, mientras exploraban un bosque m√°gico lleno de criaturas fascinantes y √°rboles centenarios, Sparkle y Rex se encontraron con un mapa antiguo que suger√≠a la existencia de un tesoro escondido en una isla lejana. Emocionados por la perspectiva de una nueva aventura, decidieron zarpar hacia los mares desconocidos y enfrentarse a los piratas que custodiaban el tesoro.*

*A lo largo de su viaje, Sparkle usaba sus poderes m√°gicos para iluminar el camino y proteger a sus amigos, mientras que Rex pasaba las noches jugando videojuegos en la cubierta del barco, siempre buscando mejorar sus habilidades. Aunque travieso, Rex demostr√≥ ser un aliado valioso cuando se enfrentaron a desaf√≠os en alta mar, utilizando su astucia para resolver problemas y derrotar a los piratas enemigos.*

*Durante una tormenta intensa, el barco qued√≥ atrapado en una isla misteriosa. Mientras exploraban la isla en busca de pistas sobre el tesoro, Sparkle y Rex se encontraron con seres m√°gicos y desaf√≠os que pusieron a prueba su amistad. Trabajaron juntos, superando obst√°culos y resolviendo enigmas hasta llegar al lugar indicado en el mapa.*

*Finalmente, encontraron el tesoro escondido, un cofre lleno de gemas resplandecientes y objetos m√°gicos. Al abrirlo, liberaron una energ√≠a m√°gica que transform√≥ la isla en un lugar a√∫n m√°s maravilloso. Los amigos regresaron a casa con sus tesoros y recuerdos inolvidables de su aventura.*

*A partir de ese d√≠a, Sparkle y Rex continuaron viviendo emocionantes experiencias, explorando bosques m√°gicos, enfrent√°ndose a piratas y disfrutando de los videojuegos bajo la luz de la luna. Su amistad √∫nica demostr√≥ que, sin importar cu√°n diferentes sean dos seres, la verdadera magia se encuentra en la conexi√≥n y la diversidad de la amistad.*


## Knowledge Integration
üçÖ Explica la t√©cnica de Knowledge Integration

ü§ñ La "Knowledge Integration" (Integraci√≥n de Conocimiento) es una t√©cnica que se refiere a la *capacidad de un modelo o sistema para combinar y utilizar de manera coherente informaci√≥n de **diversas fuentes o √°reas de conocimiento***. En el contexto de la inteligencia artificial y los modelos de lenguaje, como GPT-3.5, ***la Knowledge Integration implica la habilidad de asimilar datos de diferentes dominios y generar respuestas que integren de manera efectiva esa informaci√≥n diversa.***

ü§ñ Cuando se aplica la t√©cnica de Knowledge Integration, el modelo no solo se basa en la informaci√≥n proporcionada en el prompt, sino que tambi√©n utiliza su conocimiento previo y la comprensi√≥n del contexto para generar respuestas m√°s completas y coherentes. Esto permite al modelo integrar informaci√≥n de diversas disciplinas y proporcionar respuestas m√°s informadas y contextualmente ricas.

ü§ñ Un ejemplo de Knowledge Integration en la pr√°ctica podr√≠a ser:

**Prompt:**
```
Describe los impactos ambientales y las implicaciones econ√≥micas de la introducci√≥n de energ√≠a renovable a gran escala en la industria manufacturera.
```

ü§ñ En este caso, el modelo deber√≠a integrar conocimientos sobre energ√≠a renovable, impactos ambientales, econom√≠a y manufactura para ofrecer una respuesta completa y bien informada. La capacidad para integrar informaci√≥n de estas diferentes √°reas de conocimiento permitir√≠a al modelo generar una respuesta que vaya m√°s all√° de la informaci√≥n espec√≠fica proporcionada en el prompt.

ü§ñ üëâ Es importante se√±alar que, aunque los modelos de lenguaje pueden realizar tareas de Knowledge Integration hasta cierto punto, su capacidad para comprender el contexto y proporcionar respuestas precisas depende en gran medida de la calidad y diversidad de los datos con los que han sido entrenados. Adem√°s, siempre es necesario validar la informaci√≥n generada utilizando fuentes confiables y conocimientos establecidos para garantizar la precisi√≥n y coherencia.

üß† Knowledge Integration es la t√©cnica  que integra el conocimiento de varios dominios para resolver un problema.

üçÖ como ejemplo de la tecnica de Knowledge integration, quiero combinar el conocimiento de dos dominios, el primero el de petrofisica basica y el segundo de Python, entonces, crea una clase que cuente con una funcion que calcule la porosidad primaria de una formacion

ü§ñ Claro, puedo proporcionarte un ejemplo simple de integraci√≥n de conocimientos combinando el dominio de petrof√≠sica b√°sica y el lenguaje de programaci√≥n Python. Aqu√≠ tienes una clase que incluye una funci√≥n para calcular la porosidad primaria de una formaci√≥n:

```python
class PetrofisicaCalculadora:
    def __init__(self, densidad_matriz, densidad_fluido, densidad_grano):
        self.densidad_matriz = densidad_matriz
        self.densidad_fluido = densidad_fluido
        self.densidad_grano = densidad_grano

    def calcular_porosidad_primaria(self):
        try:
            # F√≥rmula de porosidad primaria
            porosidad_primaria = (
                (self.densidad_matriz - self.densidad_fluido) /
                (self.densidad_matriz - self.densidad_grano)
            ) * 100

            return porosidad_primaria

        except ZeroDivisionError:
            print("Error: La densidad de la matriz y la densidad del grano deben ser distintas.")

# Ejemplo de uso
if __name__ == "__main__":
    # Crear una instancia de la clase PetrofisicaCalculadora
    calculadora = PetrofisicaCalculadora(densidad_matriz=2.65, densidad_fluido=1.0, densidad_grano=2.71)

    # Calcular y mostrar la porosidad primaria
    porosidad_resultado = calculadora.calcular_porosidad_primaria()
    print(f"La porosidad primaria es: {porosidad_resultado:.2f}%")
```

ü§ñ En este ejemplo, la clase `PetrofisicaCalculadora` tiene un m√©todo llamado `calcular_porosidad_primaria`. Este m√©todo utiliza la f√≥rmula de porosidad primaria, una medida com√∫n en petrof√≠sica, que involucra las densidades de la matriz, el fluido y el grano de la formaci√≥n.

ü§ñ Este ejemplo combina conocimientos de petrof√≠sica b√°sica (la f√≥rmula de porosidad primaria) con el uso de Python para crear una clase que puede realizar este c√°lculo. Es un simple ejemplo de c√≥mo se podr√≠a integrar conocimiento de diferentes dominios para realizar tareas espec√≠ficas.

## Hiper par√°metros de ChatGPT

üçÖ Explica el concepto de hyper parametros a un ni√±o de 8 a√±os

ü§ñ ¬°Hola de nuevo! Claro, intentemos con un enfoque diferente:

ü§ñ Imagina que est√°s ense√±ando a un robot a dibujar, pero este robot tiene una varita m√°gica que puedes ajustar de diferentes maneras. Cuando ajustas la varita m√°gica, le est√°s diciendo al robot c√≥mo deber√≠a dibujar de una manera especial. Es como si le dieras reglas especiales para que sus dibujos sean los mejores.

ü§ñ Estos ajustes m√°gicos son como los "hiperpar√°metros" para el robot. Si alguna vez piensas, "Quiero que el robot haga dibujos a√∫n m√°s incre√≠bles", puedes cambiar algunos de estos ajustes m√°gicos para que el robot dibuje de una manera diferente. Tal vez quieras que sus l√≠neas sean m√°s suaves o que use colores m√°s brillantes.

ü§ñ En la inteligencia artificial, cuando ense√±amos a las computadoras a hacer cosas, tambi√©n les damos reglas especiales para que aprendan. Esos ajustes m√°gicos son los "hiperpar√°metros". Pueden ser como decirle a la computadora cu√°nto debe aprender de los datos, o cu√°nto debe enfocarse en detalles espec√≠ficos.

ü§ñ En resumen, los "hiperpar√°metros" son como los ajustes m√°gicos que les decimos a las computadoras para que hagan un trabajo realmente bueno en lo que est√°n aprendiendo. Es como darle al robot las instrucciones perfectas para que haga los mejores dibujos. ¬øC√≥mo suena ahora?

üçÖ Dame un ejemplo del uso de hyper parametros en un prompt

ü§ñ ¬°Claro! Imagina que tienes una varita m√°gica y quieres ense√±arle a una computadora a adivinar el n√∫mero que est√°s pensando. Ahora, la varita m√°gica tiene algunos ajustes especiales llamados "hiperpar√°metros". Aqu√≠ hay un ejemplo de c√≥mo podr√≠as usarlos en un "prompt":

**Prompt:**
```
Piensa en un n√∫mero del 1 al 100. Quiero que la computadora adivine ese n√∫mero, pero quiero que lo haga de la mejor manera posible. Ajusta los hiperpar√°metros para optimizar la precisi√≥n de la adivinanza. Puedes cambiar cosas como la cantidad de intentos, la velocidad de aprendizaje y la cantidad de pistas que la computadora puede utilizar.
```

ü§ñ En este prompt, est√°s dando instrucciones a la computadora sobre c√≥mo deber√≠a ajustar sus hiperpar√°metros para mejorar su capacidad para adivinar el n√∫mero que est√°s pensando. Puedes imaginarte que la computadora ajusta la "configuraci√≥n" interna (hiperpar√°metros) para mejorar su rendimiento en la tarea espec√≠fica de adivinanza.

ü§ñ Esta es solo una manera de pensar en ello, y en el mundo real, los hiperpar√°metros pueden ser ajustados para tareas m√°s complejas, como entrenar modelos de aprendizaje autom√°tico para reconocer im√°genes, traducir idiomas o cualquier otra tarea espec√≠fica que quieras que la computadora realice de la mejor manera posible.

ü§ñ Otra manera. Vamos a imaginar que tienes una varita m√°gica que te ayuda a ense√±ar a un robot a jugar un juego. Ahora, la varita tiene algunos ajustes especiales llamados "hiperpar√°metros" que puedes cambiar para que el robot sea un jugador a√∫n mejor.

**Prompt:**
```
Ens√©√±ale al robot a jugar al juego de adivinanzas. Queremos que sea muy bueno y que aprenda r√°pido. Ajusta los hiperpar√°metros de la varita m√°gica para lograrlo.
```

En este ejemplo:

1. **Tasa de Aprendizaje:** Puedes ajustar la tasa de aprendizaje para decirle al robot cu√°nto debe aprender de cada intento. Un valor alto har√° que aprenda m√°s r√°pido, pero tambi√©n podr√≠a olvidar algunas cosas. Un valor bajo har√° que aprenda m√°s lentamente, pero podr√≠a recordar mejor.

2. **N√∫mero de Intentos:** Puedes ajustar cu√°ntos intentos le das al robot para aprender. Un n√∫mero alto le dar√° m√°s oportunidades de aprender, pero tambi√©n podr√≠a tardar m√°s tiempo. Un n√∫mero bajo har√° que aprenda m√°s r√°pido, pero con menos oportunidades.

3. **Foco en Detalles o Conceptos Generales:** Puedes ajustar si quieres que el robot preste mucha atenci√≥n a detalles peque√±os o si debe concentrarse en entender conceptos m√°s grandes del juego.

Cambiar estos ajustes ser√≠a como girar los "hiperpar√°metros" en la varita m√°gica para decirle al robot c√≥mo queremos que aprenda. As√≠, al ajustar estos hiperpar√°metros, ayudamos al robot a volverse un jugador de adivinanzas muy h√°bil. ¬°Es como darle instrucciones m√°gicas para que aprenda de la mejor manera posible!

#### Hyper paramatros de temperatura y top_p
ü§ñ Los hiperpar√°metros de temperatura (temperature) y top-p son espec√≠ficos del modelo de lenguaje GPT (Generative Pre-trained Transformer) y est√°n relacionados con la generaci√≥n de texto. *Estos hiperpar√°metros se utilizan para ajustar la diversidad y la creatividad de las respuestas generadas por el modelo.*

1. **Temperatura (Temperature):**
   - **Baja Temperatura (valor cercano a 0):** Hace que el modelo sea m√°s determinista y tienda a generar respuestas m√°s predecibles y centradas en las elecciones m√°s probables.
   - **Alta Temperatura (valor mayor a 1):** Aumenta la aleatoriedad y la diversidad en las respuestas generadas, ya que permite que se exploren opciones menos probables.

   En t√©rminos sencillos, la temperatura controla cu√°nto "caos" o aleatoriedad quieres en las respuestas del modelo. Una temperatura baja tiende a producir respuestas m√°s conservadoras y coherentes, mientras que una temperatura alta puede dar lugar a respuestas m√°s sorprendentes y variadas.

2. **Top-p (tambi√©n conocido como Nucleus Sampling):**
   - **Top-p = 1.0:** Selecciona siempre la palabra m√°s probable, similar a la generaci√≥n con temperatura baja.
   - **Top-p < 1.0:** Limita la selecci√≥n a un subconjunto de las palabras m√°s probables, excluyendo palabras menos probables.

   ü§ñ El hiperpar√°metro top-p se utiliza para controlar la probabilidad acumulativa de las palabras que se consideran para la generaci√≥n de texto. Reducir top-p permite que el modelo se centre en un conjunto m√°s estrecho de opciones, eliminando las opciones menos probables.

ü§ñ Estos hiperpar√°metros son √∫tiles cuando se quiere ajustar el equilibrio entre la coherencia y la creatividad en la generaci√≥n de texto. La elecci√≥n de valores espec√≠ficos depender√° del escenario de uso y de la naturaleza deseada de las respuestas generadas. Experimentar con diferentes valores de temperatura y top-p puede ayudar a obtener el tipo de salida que mejor se adapte a tus necesidades.

üçÖ Es bueno aplicar ambos hyper parametros en un mismo prompt?

ü§ñ S√≠, es completamente v√°lido y a menudo es una buena pr√°ctica aplicar ambos hiperpar√°metros, temperatura y top-p, en un mismo prompt cuando trabajas con modelos de lenguaje como GPT. La combinaci√≥n de estos hiperpar√°metros puede ofrecer un control m√°s fino sobre la diversidad y la calidad de las respuestas generadas.

ü§ñ Por ejemplo, puedes ajustar la temperatura para controlar la aleatoriedad general de las respuestas, y al mismo tiempo, usar top-p para limitar la selecci√≥n de palabras a un conjunto m√°s estrecho de las opciones m√°s probables. Esto te permite lograr un equilibrio entre coherencia y creatividad en las respuestas generadas.

ü§ñ La combinaci√≥n de ambos hiperpar√°metros permite una mayor flexibilidad y adaptaci√≥n a las necesidades espec√≠ficas del problema o del contexto en el que est√°s utilizando el modelo de lenguaje. Es recomendable experimentar con diferentes valores de temperatura y top-p para encontrar la combinaci√≥n que mejor se ajuste a tus objetivos particulares.

üçÖ Muestra un ejemplo de estos hyper parametros en un prompt

ü§ñ Aqu√≠ tienes un ejemplo de c√≥mo podr√≠as estructurar un prompt aplicando ambos hiperpar√°metros, temperatura y top-p, en un modelo de lenguaje como GPT:

```plaintext
Genera una historia corta sobre un explorador en un bosque m√°gico. La temperatura debe ser ajustada a 0.8 y el top-p a 0.7. Queremos una historia que sea creativa pero a√∫n coherente.
```

ü§ñ En este prompt, est√°s indicando al modelo que genere una historia corta sobre un tema espec√≠fico, pero tambi√©n est√°s proporcionando instrucciones espec√≠ficas sobre la temperatura y el top-p que debe utilizar durante la generaci√≥n. La temperatura de 0.8 implica cierto grado de aleatoriedad y creatividad en las respuestas, mientras que el top-p de 0.7 restringe la selecci√≥n de palabras a un conjunto m√°s limitado, manteniendo la coherencia en cierta medida.

ü§ñ Es importante tener en cuenta que los valores espec√≠ficos de temperatura y top-p pueden variar seg√∫n el caso de uso y las preferencias personales. Experimentar con diferentes combinaciones de hiperpar√°metros te permitir√° obtener resultados que se alineen mejor con tus expectativas para la generaci√≥n de texto.

üçÖ ¬øcuales son los valores predeterminados de temperatura y top_p en GPT-3 (Dec-2023)

ü§ñ En la implementaci√≥n de GPT-3 de OpenAI, los valores predeterminados para la temperatura y top-p son los siguientes:

1. **Temperatura (Temperature):** El valor predeterminado es 1.0. Una temperatura de 1.0 implica una generaci√≥n moderadamente diversa y creativa. Valores m√°s bajos, como 0.8 o 0.5, tender√°n a producir respuestas m√°s deterministas y coherentes. Valores m√°s altos, como 1.2 o 1.5, aumentar√°n la aleatoriedad y la creatividad.

2. **Top-p (Nucleus Sampling):** El valor predeterminado para top-p es 1.0. Esto significa que se consideran todas las palabras en el vocabulario en el proceso de generaci√≥n. Al ajustar top-p a valores m√°s bajos, como 0.8 o 0.7, se excluyen las opciones menos probables, lo que puede influir en la generaci√≥n para que se centre en palabras m√°s comunes y predecibles.

üçÖ Es importante destacar que estos valores predeterminados pueden variar seg√∫n la implementaci√≥n espec√≠fica del modelo y la plataforma que est√©s utilizando. Siempre es aconsejable consultar la documentaci√≥n espec√≠fica de la API o la implementaci√≥n del modelo que est√°s utilizando para obtener informaci√≥n precisa sobre los valores predeterminados.

üëÄ Seg√∫n el profesor en el curso [Hyper parametros](https://platzi.com/new-home/clases/7296-chatgpt/61985-hiper-parametros-de-chatgpt/), no es recomendable usar ambos parametros en un mismo prompt. Este curso es del 2021

#### Hyper parametro "n"
Es el numero de respuestas o outputs que se esperan de un prompt. Este se puede indicar como sigue: n=4. Esto se comento en el curso, pero apicado a GPT-3, no funciona. Funciona mejor si le dices: dame 3 o "N" respuestas. Y lo hace

üß† üëâ Los hyper parametros **temperature** y **top_p**, son ajustes propios de GPT-3, usados en los prompts para ajustar la diversidad y la creatividad de las respuestas generadas por el modelo. 

üß† üëâ La **temperature** 0-1. Sirve para controlar la creatividad y aleatoriedad de las respuestas que se obtienen.

üß† üëâ El ajuste del **top_p** permite elevar o disminuir el uso de palabras mas comunes y predecibles. Cuando **top_p** = 1,  Selecciona siempre la palabra m√°s probable, similar a la generaci√≥n con temperatura baja. Cuando **top-p < 1.0:** Limita la selecci√≥n a un subconjunto de las palabras m√°s probables, excluyendo palabras menos probables.

üçÖ Genera una historia corta sobre un explorador en un bosque m√°gico. La temperatura debe ser ajustada a 0.8 y el top-p a 0.7. Queremos una historia que sea creativa pero a√∫n coherente.

ü§ñ . . . 

*En el coraz√≥n del Bosque Encantado, donde los √°rboles susurran melod√≠as ancestrales y las luci√©rnagas danzan como estrellas fugaces, viv√≠a un intr√©pido explorador llamado Aiden. Armado con una br√∫jula m√°gica que parpadeaba con luz centelleante, Aiden se aventur√≥ hacia lo desconocido, ansioso por descubrir los secretos ocultos del bosque.*

*La temperatura fresca del aire vibraba con energ√≠a, mientras Aiden avanzaba entre los √°rboles gigantes cuyas ramas se entrelazaban en arcos formando pasillos encantados. Cada paso revelaba criaturas m√°gicas que observaban con ojos curiosos. Mariposas multicolores tej√≠an arco√≠ris con sus alas, y los ruise√±ores transformaban sus canciones en hechizos melodiosos.*

*Siguiendo las indicaciones de su br√∫jula m√°gica, Aiden lleg√≥ a un claro lleno de flores resplandecientes que respond√≠an a su presencia con destellos de luz. En el centro del claro, descubri√≥ una antigua fuente de la que flu√≠a agua cristalina con propiedades m√≠sticas. Se acerc√≥ cauteloso, sintiendo la magia pulsar en el aire.*

*Al tocar el agua de la fuente, Aiden experiment√≥ una r√°faga de visiones. Vio el pasado del bosque, sus historias entrelazadas con la aurora boreal y sus guardianes m√°gicos que velaban por la armon√≠a. La br√∫jula parpadeaba con m√°s intensidad, gui√°ndolo hacia el coraz√≥n mismo del bosque.*

*A medida que avanzaba, los √°rboles comenzaron a susurrarle mensajes antiguos y sus ra√≠ces formaron un camino luminoso. Descubri√≥ un portal m√°gico que lo llev√≥ a una dimensi√≥n et√©rea donde los sue√±os se tej√≠an en la tela del tiempo. All√≠, conoci√≥ al Guardi√°n del Bosque, una criatura sabia que le cont√≥ la historia de la magia que sosten√≠a el equilibrio del mundo.*

*Aiden, con su alma llena de asombro, regres√≥ al Bosque Encantado. La br√∫jula, ahora resplandeciente, lo gui√≥ de vuelta a casa. Cada rinc√≥n del bosque celebr√≥ su retorno con una sinfon√≠a de luz y sonido. Aiden, el explorador, llev√≥ consigo la magia del bosque en su coraz√≥n, recordando siempre la maravilla de lo desconocido y la importancia de preservar la magia que lo envolv√≠a. Y as√≠, sus historias se sumaron a las leyendas del Bosque Encantado.*

*Fin*


[Hyper parametros de Chat-GPT](https://learn.microsoft.com/en-us/connectors/openaigpt4ip/#edit-prompt)

## Como crear contenido extenso en Chat-GPT

ChatGPT, puee ccrear contenido pero no tan extenso, a partir de un prompt. Para eso, hay tecnicas que aplican para que el modelo vaya creando contenido en base a varios prompt, que tienen una secuencia y que el modelo es capaz de hilar y corregir hasta llegar al resultado deseado.


# Casos de uso de ChatGPT
Se puede aplicar para todo lo que te imagines:

1. Creaci√≥n de herramientas como: creaci√≥n de software, resumen de texto, etc
2. Como mentor personalizado de algun tema espec√≠fico.
3. Como asistente personal


# Fuentes y referencias
- [ ] [Prompting Engineering con ChatGPT - Platzi](https://platzi.com/cursos/chatgpt/)
- [ ] [Learn Prompting org](https://learnprompting.org/es/docs/intro)

# Repaso
1. ¬øCu√°l de las siguientes es una aplicaci√≥n com√∫n de ChatGPT con prompt engineering? Creaci√≥n de contenido extenso.
2. ¬øCu√°l es una de las limitaciones de ChatGPT? Puede generar respuestas plausibles, pero incorrectas.
3. ¬øCu√°l es el objetivo principal del prompt engineering? Conocer la estructura interna de ChatGPT. REPASAR CLASE
4. ¬øCu√°les son los elementos principales en la estructura de un prompt? Instrucci√≥n, contexto, input y output.
5. Un tip de prompt engineering es ‚Äúreafirmar‚Äù con el objetivo de que el modelo IA te indique su prop√≥sito o si entendi√≥ su objetivo. ¬øEsto es verdadero o falso? Falso, esto no es necesario con los LLM actuales. REPASAR CLASE
6. ¬øQu√© es un error com√∫n al escribir un prompt para ChatGPT? Ser demasiado vago en la solicitud.
7. ¬øC√≥mo se puede mejorar un prompt para ChatGPT? Proporcionando ejemplos claros y precisos.
8. ¬øCu√°l es la diferencia entre zero-shot y one-shot prompting? La cantidad de ejemplos necesarios para que ChatGPT aprenda.
9. ¬øQu√© es la t√©cnica de chain-of-thought prompting? Estimular una conversaci√≥n continua con ChatGPT a trav√©s de una estructura de pensamiento paso a paso.
10. ¬øEn qu√© tipo de formatos o estructuras de texto puede ChatGPT entregar informaci√≥n/resultados? Todas las opciones son correctas
11. Muchas veces el modelo de IA no me dar√° en un comienzo el resultado que se necesita o espec√≠ficamente lo que busco. En ese caso puedo darle feedback/retroalimentaci√≥n continuamente sobre sus respuestas indicando qu√© me gusta, qu√© no me gusta y c√≥mo me gustar√≠a que fuera. ¬øC√≥mo le llamamos a esta t√©cnica de prompt engineering? Iterar

12. ¬øEn qu√© consiste el "role play" en el contexto de ChatGPT? Hacer que el modelo act√∫e como un personaje o profesi√≥n espec√≠fica.
13. ¬øQu√© es "knowledge generation" en el contexto de ChatGPT? Hacer que el modelo genere informaci√≥n nueva y √∫til para trabajar con esos datos.
14. ¬øQu√© hiper par√°metro de ChatGPT se utiliza para controlar el nivel de creatividad en las respuestas del LLM? Temperature
15. En el contexto de la correcci√≥n de estilos, ¬øc√≥mo puede utilizarse ChatGPT en prompt engineering? Para cambiar el estilo de escritura a uno predefinido.

