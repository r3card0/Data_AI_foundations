# ChatGPT
Es una modelo de inteligencia artificial que genera lenguaje estructurado.

- [ ] [Como escribir prompts en ChatGPT](https://github.com/r3card0/Data_AI_foundations/blob/main/topics/Prompt_Engineering_ChatGPT.md#como-escribir-prompts-en-chatgpt)
- [ ] [T√©cnicas b√°sicas de prompt engineering](https://github.com/r3card0/Data_AI_foundations/blob/main/topics/Prompt_Engineering_ChatGPT.md#t%C3%A9cnicas-b%C3%A1sicas-de-prompt-engineering)
- [ ] [T√©cnicas avanzadas de prompt engineering](https://github.com/r3card0/Data_AI_foundations/blob/main/topics/Prompt_Engineering_ChatGPT.md#t%C3%A9cnicas-avanzadas-de-prompt-engineering)
- [ ] [Casos de uso]()

# Como escribir prompts en ChatGPT
Un prompt es una pregunta que se le hace a ChatGPT. Es recomendable considerar la fecha del tema porque los modelos pueden tener informaci√≥n actuializada haste la fecha considerada. Por ejemplo, ChatGPT, en su lanzamiento, tuvo informaci√≥n hasta septiembre del 2021.

## Estructura de un prompt
Un prompt tiene los siguientes puntos que le dan estructura y son: *instrucci√≥n, contexto, inputs y outputs*. Cabe se√±alar, que no es necesario que los 4 puntos est√°n inlcuidos en un prompt.

#### Instrucci√≥n
Se trata de la tarea o instrucci√≥n a resolver. Es la tarea solicitada al modelo (ChatGPT). Esta solicitud, puede ser una pregunta simple o compleja. 

Ejemplo:
```
¬øqu√© es una base de datos relacional?
```


#### Contexto
Es informaci√≥n adicional que se le proporciona al modelo para mejorar su respuesta. 

Ejemplo:
```
ahora, explica a un ni√±o de 8 a√±os, que es una base de datos relacional con ejemplos que el entienda
```

#### Inputs
Es informaci√≥n adicional que se le proporciona al modelo para que realice comparaciones y mejorar su respuesta. Esto se da cuando se le proporciona un ejemplo al modelo para que a partir de este mejore su respuesta. Se porporciona mas detalle.

Ejemplo:
```
explicale al ni√±o, la diferencia entre la base de datos relacional y las tablas de un archivo excel
```


```
explicalo nuevamente cambiando la palabra carpeta por caja de carton, porque el ni√±o no usa carpetas
```

#### Outputs
Se refiere cuando se le solicita al modelo, que la respuesta la de en una estructura deseada, como por ejemplo que de una tabla de comparaci√≥n, o que proporcione divisiones por categoria a trav√©s de bullets num√©ricos o no num√©ricos. Este es opcional y se da cuando se brinda mas detalle al modelo para que mejore su respuesta.

```
nuevamente, explicale la diferencia entre ambas tecnologias pero ahora con una historia de piratas donde se enfrenten a dinosarios y tiburones que tienen piernas de humano y pueden respirar tanto en la superficie como en el mar
```

[ver conversacion üó∫](https://chat.openai.com/share/1f4a1d79-c8eb-4174-bfe2-ad525e2aa9b4)


# T√©cnicas b√°sicas de prompt engineering
* Zero-shot y One-shot Prompting
* Chain-of-Thought Prompting
* Optimizar resultados con estructuras de texto espec√≠ficas
* Mejorar resultados iterando


El prop√≥sito de usar *Chain-of-thought* con LLM como ChatGPT, es generar texto estructurado y coherente a partir de una l√≠nea de pensamiento como ejemplo

La principal ventaja del *zero-shot* prompting es que no requiere datos de entrenamiento adicionales

La *iteraci√≥n* en prompt engineering es una t√©cnica para orientar al modelo a dar mejores respuestas con base al feedback de sus respuestas anteriores

La principal diferencia entre *few-shot* prompting y *one-prompting* es que *few-shot* prompting puede obtener una precisi√≥n mayor con unos cuantos ejemplos de entrenamiento. *One-shot* prompting puede ser menos preciso debido a que utiliza solo un ejemplo de entramiento.

# T√©cnicas avanzadas de prompt engineering
* Role play
* knowledge Generation / Knowledge Integration
* Hiper par√°metros de ChatGPT

## Role play
## Knowledge Generation / Knowledge Integration
Son t√©cnicas usadas para mejorar los modelos de lenguaje y que incluye la capacidad de generar y/o incorporar conocimiento o informaci√≥n para ayudar al modelo a generar respuestas mucho mas precisas.

### Knowledge Generation
üçÖ ¬øQue me puedes decir del concepto de Knowledge Generation aplicado en prompts?

ü§ñ ¬°Hola! En el contexto de la inteligencia artificial y los modelos de lenguaje como GPT-3.5, el concepto de "Knowledge Generation" (Generaci√≥n de Conocimiento) *se refiere a la capacidad del modelo para generar informaci√≥n nueva y relevante en funci√≥n de los datos y el contexto proporcionados en el prompt.*

ü§ñ Cuando aplicas el concepto de Knowledge Generation en prompts, *est√°s aprovechando la capacidad del modelo para comprender el contexto y generar respuestas que no solo se basan en la informaci√≥n existente en sus datos de entrenamiento, sino que tambi√©n incorporan una capacidad para razonar, inferir y, en ciertos casos, generar contenido nuevo.*

ü§ñ En la pr√°ctica, al utilizar prompts espec√≠ficos, puedes solicitar al modelo que genere informaci√≥n o respuestas que vayan m√°s all√° de la informaci√≥n que ha sido directamente alimentada durante su entrenamiento. Esto permite que el modelo sea m√°s vers√°til y capaz de ofrecer respuestas √∫nicas y contextualmente relevantes en una amplia gama de situaciones.

ü§ñ üëâ Es importante se√±alar que, aunque los modelos de lenguaje como GPT-3.5 pueden generar conocimiento nuevo hasta cierto punto, no tienen una comprensi√≥n real del mundo y pueden producir respuestas que no son necesariamente precisas o ver√≠dicas. Por lo tanto, es fundamental interpretar y validar la informaci√≥n generada por estos modelos en funci√≥n de la precisi√≥n y la coherencia con el conocimiento establecido.

Un buen ejemplo es la capacidad del LLMs de crear historias. En base a un contexto que se proporciona en el prompt, el modelo crea una historia.

üçÖ Crea una historia donde haya dos personajes principales, un unicornio con poderes magicos, que hable y que cague dulces y un tiranosaurio rex que habla, le gusta mucho jugar videojuegos y sea un poco travieso. Ambos personajes no miden mas de 1.5m y siempre estan juntos viviendo aventuras en un mundo donde hay bosques magicos y piratas de alta mar.

ü§ñ *En un mundo m√°gico lleno de bosques encantados y oc√©anos misteriosos, viv√≠an dos amigos inusuales: Sparkle, un peque√±o unicornio con poderes m√°gicos y la habilidad √∫nica de cagar dulces, y Rex, un tiranosaurio rex parlante aficionado a los videojuegos y un tanto travieso. A pesar de sus diferencias, ambos med√≠an no m√°s de 1.5 metros y compart√≠an una amistad √∫nica y especial.*

ü§ñ *Un d√≠a, mientras exploraban un bosque m√°gico lleno de criaturas fascinantes y √°rboles centenarios, Sparkle y Rex se encontraron con un mapa antiguo que suger√≠a la existencia de un tesoro escondido en una isla lejana. Emocionados por la perspectiva de una nueva aventura, decidieron zarpar hacia los mares desconocidos y enfrentarse a los piratas que custodiaban el tesoro.*

*A lo largo de su viaje, Sparkle usaba sus poderes m√°gicos para iluminar el camino y proteger a sus amigos, mientras que Rex pasaba las noches jugando videojuegos en la cubierta del barco, siempre buscando mejorar sus habilidades. Aunque travieso, Rex demostr√≥ ser un aliado valioso cuando se enfrentaron a desaf√≠os en alta mar, utilizando su astucia para resolver problemas y derrotar a los piratas enemigos.*

*Durante una tormenta intensa, el barco qued√≥ atrapado en una isla misteriosa. Mientras exploraban la isla en busca de pistas sobre el tesoro, Sparkle y Rex se encontraron con seres m√°gicos y desaf√≠os que pusieron a prueba su amistad. Trabajaron juntos, superando obst√°culos y resolviendo enigmas hasta llegar al lugar indicado en el mapa.*

*Finalmente, encontraron el tesoro escondido, un cofre lleno de gemas resplandecientes y objetos m√°gicos. Al abrirlo, liberaron una energ√≠a m√°gica que transform√≥ la isla en un lugar a√∫n m√°s maravilloso. Los amigos regresaron a casa con sus tesoros y recuerdos inolvidables de su aventura.*

*A partir de ese d√≠a, Sparkle y Rex continuaron viviendo emocionantes experiencias, explorando bosques m√°gicos, enfrent√°ndose a piratas y disfrutando de los videojuegos bajo la luz de la luna. Su amistad √∫nica demostr√≥ que, sin importar cu√°n diferentes sean dos seres, la verdadera magia se encuentra en la conexi√≥n y la diversidad de la amistad.*


### Knowledge Integration
üçÖ Explica la t√©cnica de Knowledge Integration

ü§ñ La "Knowledge Integration" (Integraci√≥n de Conocimiento) es una t√©cnica que se refiere a la *capacidad de un modelo o sistema para combinar y utilizar de manera coherente informaci√≥n de **diversas fuentes o √°reas de conocimiento***. En el contexto de la inteligencia artificial y los modelos de lenguaje, como GPT-3.5, ***la Knowledge Integration implica la habilidad de asimilar datos de diferentes dominios y generar respuestas que integren de manera efectiva esa informaci√≥n diversa.***

ü§ñ Cuando se aplica la t√©cnica de Knowledge Integration, el modelo no solo se basa en la informaci√≥n proporcionada en el prompt, sino que tambi√©n utiliza su conocimiento previo y la comprensi√≥n del contexto para generar respuestas m√°s completas y coherentes. Esto permite al modelo integrar informaci√≥n de diversas disciplinas y proporcionar respuestas m√°s informadas y contextualmente ricas.

ü§ñ Un ejemplo de Knowledge Integration en la pr√°ctica podr√≠a ser:

**Prompt:**
```
Describe los impactos ambientales y las implicaciones econ√≥micas de la introducci√≥n de energ√≠a renovable a gran escala en la industria manufacturera.
```

ü§ñ En este caso, el modelo deber√≠a integrar conocimientos sobre energ√≠a renovable, impactos ambientales, econom√≠a y manufactura para ofrecer una respuesta completa y bien informada. La capacidad para integrar informaci√≥n de estas diferentes √°reas de conocimiento permitir√≠a al modelo generar una respuesta que vaya m√°s all√° de la informaci√≥n espec√≠fica proporcionada en el prompt.

ü§ñ üëâ Es importante se√±alar que, aunque los modelos de lenguaje pueden realizar tareas de Knowledge Integration hasta cierto punto, su capacidad para comprender el contexto y proporcionar respuestas precisas depende en gran medida de la calidad y diversidad de los datos con los que han sido entrenados. Adem√°s, siempre es necesario validar la informaci√≥n generada utilizando fuentes confiables y conocimientos establecidos para garantizar la precisi√≥n y coherencia.

üß† Knowledge Integration es la t√©cnica  que integra el conocimiento de varios dominios para resolver un problema.

üçÖ como ejemplo de la tecnica de Knowledge integration, quiero combinar el conocimiento de dos dominios, el primero el de petrofisica basica y el segundo de Python, entonces, crea una clase que cuente con una funcion que calcule la porosidad primaria de una formacion

ü§ñ Claro, puedo proporcionarte un ejemplo simple de integraci√≥n de conocimientos combinando el dominio de petrof√≠sica b√°sica y el lenguaje de programaci√≥n Python. Aqu√≠ tienes una clase que incluye una funci√≥n para calcular la porosidad primaria de una formaci√≥n:

```python
class PetrofisicaCalculadora:
    def __init__(self, densidad_matriz, densidad_fluido, densidad_grano):
        self.densidad_matriz = densidad_matriz
        self.densidad_fluido = densidad_fluido
        self.densidad_grano = densidad_grano

    def calcular_porosidad_primaria(self):
        try:
            # F√≥rmula de porosidad primaria
            porosidad_primaria = (
                (self.densidad_matriz - self.densidad_fluido) /
                (self.densidad_matriz - self.densidad_grano)
            ) * 100

            return porosidad_primaria

        except ZeroDivisionError:
            print("Error: La densidad de la matriz y la densidad del grano deben ser distintas.")

# Ejemplo de uso
if __name__ == "__main__":
    # Crear una instancia de la clase PetrofisicaCalculadora
    calculadora = PetrofisicaCalculadora(densidad_matriz=2.65, densidad_fluido=1.0, densidad_grano=2.71)

    # Calcular y mostrar la porosidad primaria
    porosidad_resultado = calculadora.calcular_porosidad_primaria()
    print(f"La porosidad primaria es: {porosidad_resultado:.2f}%")
```

ü§ñ En este ejemplo, la clase `PetrofisicaCalculadora` tiene un m√©todo llamado `calcular_porosidad_primaria`. Este m√©todo utiliza la f√≥rmula de porosidad primaria, una medida com√∫n en petrof√≠sica, que involucra las densidades de la matriz, el fluido y el grano de la formaci√≥n.

ü§ñ Este ejemplo combina conocimientos de petrof√≠sica b√°sica (la f√≥rmula de porosidad primaria) con el uso de Python para crear una clase que puede realizar este c√°lculo. Es un simple ejemplo de c√≥mo se podr√≠a integrar conocimiento de diferentes dominios para realizar tareas espec√≠ficas.

## Hiper par√°metros de ChatGPT

üçÖ Explica el concepto de hyper parametros a un ni√±o de 8 a√±os

ü§ñ ¬°Hola de nuevo! Claro, intentemos con un enfoque diferente:

ü§ñ Imagina que est√°s ense√±ando a un robot a dibujar, pero este robot tiene una varita m√°gica que puedes ajustar de diferentes maneras. Cuando ajustas la varita m√°gica, le est√°s diciendo al robot c√≥mo deber√≠a dibujar de una manera especial. Es como si le dieras reglas especiales para que sus dibujos sean los mejores.

ü§ñ Estos ajustes m√°gicos son como los "hiperpar√°metros" para el robot. Si alguna vez piensas, "Quiero que el robot haga dibujos a√∫n m√°s incre√≠bles", puedes cambiar algunos de estos ajustes m√°gicos para que el robot dibuje de una manera diferente. Tal vez quieras que sus l√≠neas sean m√°s suaves o que use colores m√°s brillantes.

ü§ñ En la inteligencia artificial, cuando ense√±amos a las computadoras a hacer cosas, tambi√©n les damos reglas especiales para que aprendan. Esos ajustes m√°gicos son los "hiperpar√°metros". Pueden ser como decirle a la computadora cu√°nto debe aprender de los datos, o cu√°nto debe enfocarse en detalles espec√≠ficos.

ü§ñ En resumen, los "hiperpar√°metros" son como los ajustes m√°gicos que les decimos a las computadoras para que hagan un trabajo realmente bueno en lo que est√°n aprendiendo. Es como darle al robot las instrucciones perfectas para que haga los mejores dibujos. ¬øC√≥mo suena ahora?

üçÖ Dame un ejemplo del uso de hyper parametros en un prompt

ü§ñ ¬°Claro! Imagina que tienes una varita m√°gica y quieres ense√±arle a una computadora a adivinar el n√∫mero que est√°s pensando. Ahora, la varita m√°gica tiene algunos ajustes especiales llamados "hiperpar√°metros". Aqu√≠ hay un ejemplo de c√≥mo podr√≠as usarlos en un "prompt":

**Prompt:**
```
Piensa en un n√∫mero del 1 al 100. Quiero que la computadora adivine ese n√∫mero, pero quiero que lo haga de la mejor manera posible. Ajusta los hiperpar√°metros para optimizar la precisi√≥n de la adivinanza. Puedes cambiar cosas como la cantidad de intentos, la velocidad de aprendizaje y la cantidad de pistas que la computadora puede utilizar.
```

ü§ñ En este prompt, est√°s dando instrucciones a la computadora sobre c√≥mo deber√≠a ajustar sus hiperpar√°metros para mejorar su capacidad para adivinar el n√∫mero que est√°s pensando. Puedes imaginarte que la computadora ajusta la "configuraci√≥n" interna (hiperpar√°metros) para mejorar su rendimiento en la tarea espec√≠fica de adivinanza.

ü§ñ Esta es solo una manera de pensar en ello, y en el mundo real, los hiperpar√°metros pueden ser ajustados para tareas m√°s complejas, como entrenar modelos de aprendizaje autom√°tico para reconocer im√°genes, traducir idiomas o cualquier otra tarea espec√≠fica que quieras que la computadora realice de la mejor manera posible.

ü§ñ Otra manera. Vamos a imaginar que tienes una varita m√°gica que te ayuda a ense√±ar a un robot a jugar un juego. Ahora, la varita tiene algunos ajustes especiales llamados "hiperpar√°metros" que puedes cambiar para que el robot sea un jugador a√∫n mejor.

**Prompt:**
```
Ens√©√±ale al robot a jugar al juego de adivinanzas. Queremos que sea muy bueno y que aprenda r√°pido. Ajusta los hiperpar√°metros de la varita m√°gica para lograrlo.
```

En este ejemplo:

1. **Tasa de Aprendizaje:** Puedes ajustar la tasa de aprendizaje para decirle al robot cu√°nto debe aprender de cada intento. Un valor alto har√° que aprenda m√°s r√°pido, pero tambi√©n podr√≠a olvidar algunas cosas. Un valor bajo har√° que aprenda m√°s lentamente, pero podr√≠a recordar mejor.

2. **N√∫mero de Intentos:** Puedes ajustar cu√°ntos intentos le das al robot para aprender. Un n√∫mero alto le dar√° m√°s oportunidades de aprender, pero tambi√©n podr√≠a tardar m√°s tiempo. Un n√∫mero bajo har√° que aprenda m√°s r√°pido, pero con menos oportunidades.

3. **Foco en Detalles o Conceptos Generales:** Puedes ajustar si quieres que el robot preste mucha atenci√≥n a detalles peque√±os o si debe concentrarse en entender conceptos m√°s grandes del juego.

Cambiar estos ajustes ser√≠a como girar los "hiperpar√°metros" en la varita m√°gica para decirle al robot c√≥mo queremos que aprenda. As√≠, al ajustar estos hiperpar√°metros, ayudamos al robot a volverse un jugador de adivinanzas muy h√°bil. ¬°Es como darle instrucciones m√°gicas para que aprenda de la mejor manera posible!

#### Hyper paramatros de temperatura y top_p
ü§ñ Los hiperpar√°metros de temperatura (temperature) y top-p son espec√≠ficos del modelo de lenguaje GPT (Generative Pre-trained Transformer) y est√°n relacionados con la generaci√≥n de texto. Estos hiperpar√°metros se utilizan para ajustar la diversidad y la creatividad de las respuestas generadas por el modelo.

1. **Temperatura (Temperature):**
   - **Baja Temperatura (valor cercano a 0):** Hace que el modelo sea m√°s determinista y tienda a generar respuestas m√°s predecibles y centradas en las elecciones m√°s probables.
   - **Alta Temperatura (valor mayor a 1):** Aumenta la aleatoriedad y la diversidad en las respuestas generadas, ya que permite que se exploren opciones menos probables.

   En t√©rminos sencillos, la temperatura controla cu√°nto "caos" o aleatoriedad quieres en las respuestas del modelo. Una temperatura baja tiende a producir respuestas m√°s conservadoras y coherentes, mientras que una temperatura alta puede dar lugar a respuestas m√°s sorprendentes y variadas.

2. **Top-p (tambi√©n conocido como Nucleus Sampling):**
   - **Top-p = 1.0:** Selecciona siempre la palabra m√°s probable, similar a la generaci√≥n con temperatura baja.
   - **Top-p < 1.0:** Limita la selecci√≥n a un subconjunto de las palabras m√°s probables, excluyendo palabras menos probables.

   ü§ñ El hiperpar√°metro top-p se utiliza para controlar la probabilidad acumulativa de las palabras que se consideran para la generaci√≥n de texto. Reducir top-p permite que el modelo se centre en un conjunto m√°s estrecho de opciones, eliminando las opciones menos probables.

ü§ñ Estos hiperpar√°metros son √∫tiles cuando se quiere ajustar el equilibrio entre la coherencia y la creatividad en la generaci√≥n de texto. La elecci√≥n de valores espec√≠ficos depender√° del escenario de uso y de la naturaleza deseada de las respuestas generadas. Experimentar con diferentes valores de temperatura y top-p puede ayudar a obtener el tipo de salida que mejor se adapte a tus necesidades.

# Casos de uso de ChatGPT
